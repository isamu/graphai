import{sleep as e}from"graphai";var t,o={};var s,r=(t||(t=1,s=o,Object.defineProperty(s,"__esModule",{value:!0}),s.getMessages=s.getMergeValue=s.flatString=void 0,s.flatString=e=>Array.isArray(e)?e.filter((e=>e)).join("\n"):e??"",s.getMergeValue=(e,t,o,r)=>{const n=e[o],a=t[o];return n||a?[(0,s.flatString)(n),(0,s.flatString)(a)].filter((e=>e)).join("\n"):(0,s.flatString)(r)},void(s.getMessages=(e,t)=>[...e?[{role:"system",content:e}]:[],...t??[]])),o);const n=(e,t)=>{const o=e?.choices[0]&&e?.choices[0].message?e?.choices[0].message:null,s=o&&o.content?o.content:null,r=o?.tool_calls&&o?.tool_calls[0]?o?.tool_calls[0]:null,n=r?{id:r.id,name:r?.function?.name,arguments:(()=>{try{return JSON.parse(r?.function?.arguments)}catch(e){return}})()}:void 0;return o&&t.push(o),{...e,text:s,tool:n,message:o,messages:t}},a="this is response result",p={object:"chat.completion",id:"chatcmpl-9N7HxXYbwjmdbdiQE94MHoVluQhyt",choices:[{message:{role:"assistant",content:a},finish_reason:"stop",index:0,logprobs:null}],created:1715296589,model:"gpt-3.5-turbo-0125"},i={name:"openAIFetchAgent",agent:async({filterParams:e,params:t,namedInputs:o,config:s})=>{const{verbose:a,system:p,images:i,temperature:c,tools:l,tool_choice:m,max_tokens:g,prompt:y,messages:u,response_format:h}={...t,...o},{apiKey:b,stream:d,baseURL:f}={...t,...s||{}},_=r.getMergeValue(o,t,"mergeablePrompts",y),j=r.getMergeValue(o,t,"mergeableSystem",p),k=r.getMessages(j,u);if(!b)throw new Error("OPENAI_API_KEY key is not set in params. params: {apiKey: 'sk-xxx'}");if(_&&k.push({role:"user",content:_}),i){const e="gpt-4-vision-preview"===t.model?i[0]:{url:i[0],detail:"high"};k.push({role:"user",content:[{type:"image_url",image_url:e}]})}a&&console.log(k);const x={model:t.model||"gpt-4o",messages:k,tools:l,tool_choice:m,max_tokens:g,temperature:c??.7,stream:!!d,response_format:h},O=f??"https://api.openai.com/v1",w=await fetch(O+"/chat/completions",{method:"POST",headers:{"Content-Type":"application/json",Authorization:`Bearer ${b}`},body:JSON.stringify(x)});if(!d){if(200===w.status){const e=await w.json();return n(e,k)}throw new Error("OPENAI API Error")}const v=w.body?.getReader();if(200!==w.status||!v)throw new Error("Request failed");const A=new TextDecoder("utf-8");let M=!1;const S=[];let E="";for(;!M;){const{done:t,value:o}=await v.read();if(t)M=t,v.releaseLock();else{E=A.decode(o,{stream:!0})+E;const t=E.split(/\n+/),s=[];for(const o of t)try{const t=o.replace(/^data:\s*/,"");if("[DONE]"===t)break;if(t){const o=JSON.parse(t).choices[0].delta.content;o&&(S.push(o),e&&e.streamTokenCallback&&o&&e.streamTokenCallback(o))}}catch(e){s.push(o)}E=s.join("\n")}}return n({choices:[{message:{role:"assistant",content:S.join(""),refusal:""}}]},k)},mock:async({filterParams:t})=>{for await(const o of a.split(""))t&&t.streamTokenCallback&&o&&(await e(100),t.streamTokenCallback(o));return p},inputs:{type:"object",properties:{model:{type:"string"},system:{type:"string"},tools:{type:"object"},tool_choice:{anyOf:[{type:"array"},{type:"object"}]},max_tokens:{type:"number"},verbose:{type:"boolean"},temperature:{type:"number"},baseURL:{type:"string"},apiKey:{anyOf:[{type:"string"},{type:"object"}]},stream:{type:"boolean"},prompt:{type:"string",description:"query string"},messages:{anyOf:[{type:"string"},{type:"object"},{type:"array"}],description:"chat messages"}}},output:{type:"object",properties:{id:{type:"string"},object:{type:"string"},created:{type:"integer"},model:{type:"string"},choices:{type:"array",items:[{type:"object",properties:{index:{type:"integer"},message:{type:"array",items:[{type:"object",properties:{content:{type:"string"},role:{type:"string"}},required:["content","role"]}]}},required:["index","message","logprobs","finish_reason"]}]},usage:{type:"object",properties:{prompt_tokens:{type:"integer"},completion_tokens:{type:"integer"},total_tokens:{type:"integer"}},required:["prompt_tokens","completion_tokens","total_tokens"]},text:{type:"string"},tool:{arguments:{type:"object"},name:{type:"string"}},message:{type:"object",properties:{content:{type:"string"},role:{type:"string"}},required:["content","role"]}},required:["id","object","created","model","choices","usage"]},params:{type:"object",properties:{model:{type:"string"},system:{type:"string"},tools:{type:"object"},tool_choice:{anyOf:[{type:"array"},{type:"object"}]},max_tokens:{type:"number"},verbose:{type:"boolean"},temperature:{type:"number"},baseURL:{type:"string"},apiKey:{anyOf:[{type:"string"},{type:"object"}]},stream:{type:"boolean"},prompt:{type:"string",description:"query string"},messages:{anyOf:[{type:"string"},{type:"object"},{type:"array"}],description:"chat messages"}}},outputFormat:{llmResponse:{key:"choices.$0.message.content",type:"string"}},samples:[{inputs:{prompt:a},params:{},result:p}],description:"OpenAI Fetch Agent",category:["llm"],author:"Receptron team",repository:"https://github.com/receptron/graphai",source:"https://github.com/receptron/graphai/blob/main/llm_agents/openai_fetch_agent/src/openai_fetch_agent.ts",package:"@graphai/openai_fetch_agent",license:"MIT",stream:!0,npms:["openai"]};export{i as openAIFetchAgent};
//# sourceMappingURL=bundle.esm.min.js.map
