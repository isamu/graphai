import{sleep as e}from"graphai";var t,o={};var s,r=(t||(t=1,s=o,Object.defineProperty(s,"__esModule",{value:!0}),s.llmMetaDataFirstTokenTime=s.llmMetaDataEndTime=s.initLLMMetaData=s.convertMeta=s.getMessages=s.getMergeValue=s.flatString=void 0,s.flatString=e=>Array.isArray(e)?e.filter((e=>e)).join("\n"):e??"",s.getMergeValue=(e,t,o,r)=>{const n=e[o],a=t[o];return n||a?[(0,s.flatString)(n),(0,s.flatString)(a)].filter((e=>e)).join("\n"):(0,s.flatString)(r)},s.getMessages=(e,t)=>[...e?[{role:"system",content:e}]:[],...t??[]],s.convertMeta=e=>{const{start:t,firstToken:o,end:s}=e.timing,r=o?o-t:void 0,n=o?s-o:void 0,a=s-t;return{timing:{start:new Date(t).toISOString(),firstToken:o?new Date(o).toISOString():void 0,end:new Date(s).toISOString(),latencyToFirstToken:r,duration:n,totalElapsed:a}}},s.initLLMMetaData=()=>({timing:{start:Date.now(),end:0,totalElapsed:0}}),s.llmMetaDataEndTime=e=>{e.timing.end=Date.now()},void(s.llmMetaDataFirstTokenTime=e=>{void 0===e.timing.firstToken&&(e.timing.firstToken=Date.now())})),o);const n=(e,t)=>{const o=e?.choices[0]&&e?.choices[0].message?e?.choices[0].message:null,s=o&&o.content?o.content:null,r=o?.tool_calls&&o?.tool_calls[0]?o?.tool_calls[0]:null,n=r?{id:r.id,name:r?.function?.name,arguments:(()=>{try{return JSON.parse(r?.function?.arguments)}catch(e){return}})()}:void 0;return o&&t.push(o),{...e,text:s,tool:n,message:o,messages:t}},a="this is response result",i={object:"chat.completion",id:"chatcmpl-9N7HxXYbwjmdbdiQE94MHoVluQhyt",choices:[{message:{role:"assistant",content:a},finish_reason:"stop",index:0,logprobs:null}],created:1715296589,model:"gpt-3.5-turbo-0125"},p={name:"openAIFetchAgent",agent:async({filterParams:e,params:t,namedInputs:o,config:s})=>{const{verbose:a,system:i,images:p,temperature:c,tools:l,tool_choice:m,max_tokens:g,prompt:y,messages:u,response_format:d}={...t,...o},{apiKey:h,stream:b,baseURL:f}={...t,...s||{}},_=r.getMergeValue(o,t,"mergeablePrompts",y),k=r.getMergeValue(o,t,"mergeableSystem",i),j=r.getMessages(k,u);if(!h)throw new Error("OPENAI_API_KEY key is not set in params. params: {apiKey: 'sk-xxx'}");if(_&&j.push({role:"user",content:_}),p){const e="gpt-4-vision-preview"===t.model?p[0]:{url:p[0],detail:"high"};j.push({role:"user",content:[{type:"image_url",image_url:e}]})}a&&console.log(j);const w={model:t.model||"gpt-4o",messages:j,tools:l,tool_choice:m,max_tokens:g,temperature:c??.7,stream:!!b,response_format:d},M=f??"https://api.openai.com/v1",T=await fetch(M+"/chat/completions",{method:"POST",headers:{"Content-Type":"application/json",Authorization:`Bearer ${h}`},body:JSON.stringify(w)});if(!b){if(200===T.status){const e=await T.json();return n(e,j)}throw new Error("OPENAI API Error")}const v=T.body?.getReader();if(200!==T.status||!v)throw new Error("Request failed");const O=new TextDecoder("utf-8");let S=!1;const x=[];let D="";for(;!S;){const{done:t,value:o}=await v.read();if(t)S=t,v.releaseLock();else{D=O.decode(o,{stream:!0})+D;const t=D.split(/\n+/),s=[];for(const o of t)try{const t=o.replace(/^data:\s*/,"");if("[DONE]"===t)break;if(t){const o=JSON.parse(t).choices[0].delta.content;o&&(x.push(o),e&&e.streamTokenCallback&&o&&e.streamTokenCallback(o))}}catch(e){s.push(o)}D=s.join("\n")}}return n({choices:[{message:{role:"assistant",content:x.join(""),refusal:""}}]},j)},mock:async({filterParams:t})=>{for await(const o of a.split(""))t&&t.streamTokenCallback&&o&&(await e(100),t.streamTokenCallback(o));return i},inputs:{type:"object",properties:{model:{type:"string"},system:{type:"string"},tools:{type:"object"},tool_choice:{anyOf:[{type:"array"},{type:"object"}]},max_tokens:{type:"number"},verbose:{type:"boolean"},temperature:{type:"number"},baseURL:{type:"string"},apiKey:{anyOf:[{type:"string"},{type:"object"}]},stream:{type:"boolean"},prompt:{type:"string",description:"query string"},messages:{anyOf:[{type:"string"},{type:"object"},{type:"array"}],description:"chat messages"}}},output:{type:"object",properties:{id:{type:"string"},object:{type:"string"},created:{type:"integer"},model:{type:"string"},choices:{type:"array",items:[{type:"object",properties:{index:{type:"integer"},message:{type:"array",items:[{type:"object",properties:{content:{type:"string"},role:{type:"string"}},required:["content","role"]}]}},required:["index","message","logprobs","finish_reason"]}]},usage:{type:"object",properties:{prompt_tokens:{type:"integer"},completion_tokens:{type:"integer"},total_tokens:{type:"integer"}},required:["prompt_tokens","completion_tokens","total_tokens"]},text:{type:"string"},tool:{arguments:{type:"object"},name:{type:"string"}},message:{type:"object",properties:{content:{type:"string"},role:{type:"string"}},required:["content","role"]}},required:["id","object","created","model","choices","usage"]},params:{type:"object",properties:{model:{type:"string"},system:{type:"string"},tools:{type:"object"},tool_choice:{anyOf:[{type:"array"},{type:"object"}]},max_tokens:{type:"number"},verbose:{type:"boolean"},temperature:{type:"number"},baseURL:{type:"string"},apiKey:{anyOf:[{type:"string"},{type:"object"}]},stream:{type:"boolean"},prompt:{type:"string",description:"query string"},messages:{anyOf:[{type:"string"},{type:"object"},{type:"array"}],description:"chat messages"}}},outputFormat:{llmResponse:{key:"choices.$0.message.content",type:"string"}},samples:[{inputs:{prompt:a},params:{},result:i}],description:"OpenAI Fetch Agent",category:["llm"],author:"Receptron team",repository:"https://github.com/receptron/graphai",source:"https://github.com/receptron/graphai/blob/main/llm_agents/openai_fetch_agent/src/openai_fetch_agent.ts",package:"@graphai/openai_fetch_agent",license:"MIT",stream:!0,npms:["openai"]};export{p as openAIFetchAgent};
//# sourceMappingURL=bundle.esm.min.js.map
